% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/METRICS.R
\name{f1_score}
\alias{f1_score}
\title{F1 - Score}
\usage{
f1_score(predict, actual)
}
\arguments{
\item{predict}{A vector of predicted class labels. Must be labeled as 1 and 2.}

\item{actual}{A vector of actual class labels. Must be labeled as 1 and 2.}
}
\value{
F1 score. Values range from 0 to 1.
}
\description{
\code{f1_score} calculates F1 score for a model's prediction.
Focuses on the balance between false positives (Precision) and false negatives (Recall).
Harmonic mean of precision and recall. Places more emphasis on correctly identifying the minority class.
Does not directly account for true negatives. No symmetry between classes.

Best use case: Use F1 Score when dealing with imbalanced datasets and focusing on the positive class.
}
\examples{
n <- 1000
x1 <- runif(n, 1, 10)
x2 <- runif(n, 1, 10)
x <- cbind(x1, x2)
y <- as.factor(ifelse(3 < x1 & x1 < 7 & 3 < x2 & x2 < 7, "A", "B"))

#' # testing the performance
i_train <- sample(1:n, round(n*0.8))

x_train <- x[i_train,]
y_train <- y[i_train]

x_test <- x[-i_train,]
y_test <- y[-i_train]

m_pcccd <- pcccd(x = x_train, y = y_train, tau = 1)
p_pred <- classify_pcccd(pcccd = m_pcccd, newdata = x_test)

m_rwcccd <- rwcccd(x = x_train, y = y_train)
r_pred <- classify_rwcccd(rwcccd = m_rwcccd, newdata = x_test, e = 1)

f1_score(as.numeric(as.factor(p_pred)), as.numeric(as.factor(y_test)))


}
\author{
Jordan Eckert
}
