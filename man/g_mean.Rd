% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/METRICS.R
\name{g_mean}
\alias{g_mean}
\title{Geometric Mean}
\usage{
g_mean(predict, actual)
}
\arguments{
\item{predict}{A vector of predicted class labels. Must be labeled as 1 and 2.}

\item{actual}{A vector of actual class labels. Must be labeled as 1 and 2.}
}
\value{
Geometric Mean. Values range from 0 to 1
}
\description{
\code{g_mean} calculates geometric mean of sensitivity (recall) and specificity.
Indicates the balance between correctly identifying positive and negative classes.
Accounts for both sensitivity and specificity, ensuring no bias toward any class.
Less commonly used compared to AUC and F1 Score, making it harder to compare across studies.

Best use case: When maintaining performance for both classes is equally important, especially in imbalanced datasets.
}
\examples{
n <- 1000
x1 <- runif(n, 1, 10)
x2 <- runif(n, 1, 10)
x <- cbind(x1, x2)
y <- as.factor(ifelse(3 < x1 & x1 < 7 & 3 < x2 & x2 < 7, "A", "B"))

#' # testing the performance
i_train <- sample(1:n, round(n*0.8))

x_train <- x[i_train,]
y_train <- y[i_train]

x_test <- x[-i_train,]
y_test <- y[-i_train]

m_pcccd <- pcccd(x = x_train, y = y_train, tau = 1)
p_pred <- classify_pcccd(pcccd = m_pcccd, newdata = x_test)

g_mean(as.numeric(as.factor(p_pred)), as.numeric(as.factor(y_test)))

}
\author{
Jordan Eckert
}
